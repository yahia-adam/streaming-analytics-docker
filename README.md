# Projet de Conteneurisation - Streaming Analytics Platform

**Objectif** : DÃ©monstration des bonnes pratiques de conteneurisation avec Docker en crÃ©ant une plateforme de streaming analytics complÃ¨te.

Ce projet illustre la conteneurisation d'une architecture microservices complexe utilisant Apache Kafka, Spark et PostgreSQL.

## ğŸ¯ Objectif du Projet

Le but principal est de **conteneuriser une application de streaming analytics** en respectant les meilleures pratiques Docker :
- Isolation des services
- Gestion des rÃ©seaux et volumes
- Configuration sÃ©curisÃ©e
- Optimisation des performances
- Orchestration multi-conteneurs

## ğŸ“‹ Installation et DÃ©marrage

### Ã‰tape 1 : Installation
```bash
git clone git@github.com:yahia-adam/streaming-analytics-docker.git && cd streaming-analytics-docker
```

### Ã‰tape 2 : Configuration

```bash
mv env.exemple .env && cat .env
```



## ğŸ–ï¸ Utilisaation

### DÃ©marrage

```bash
docker compose up
```

### Streamlit Dashboard
```bash
http://localhost:8501
```
### Producer Spark UI
```bash
http://localhost:4040
```
### Consumer Spark UI

```bash
http://localhost:4041
```

## ğŸ—ï¸ Architecture ConteneurisÃ©e

### Structure des Conteneurs

![architecture du projet](architecture.png)

### RÃ©seaux Docker

- **engnetwork** (interne) : Communication Kafka/Spark
- **dbNetwork** (interne) : AccÃ¨s base de donnÃ©es
- **webNetwork** (public) : Interface utilisateur

## ğŸ”§ Bonnes Pratiques de Conteneurisation ImplÃ©mentÃ©es

### ğŸ³ Images Docker

```dockerfile
# Utilisation d'images base officielles
FROM openjdk:11
FROM python:3.10
FROM postgres:15

# Optimisation des couches
RUN curl -fsSL https://archive.apache.org/dist/spark/... | tar -xz -C /opt && \
    ln -s /opt/spark-3.5.0-bin-hadoop3 /opt/spark
```

### ğŸ”’ SÃ©curitÃ©

- **Gestion des secrets** : Variables d'environnement via `.env`
- **Isolation rÃ©seau** : RÃ©seaux internes et publics sÃ©parÃ©s
- **Images officielles** : Utilisation d'images maintenues et sÃ©curisÃ©es
- **Principe du moindre privilÃ¨ge** : Limitation des accÃ¨s rÃ©seau

### ğŸ“Š Monitoring et Debugging

```bash
# Surveillance des conteneurs
docker-compose ps
docker stats

# AccÃ¨s aux logs
docker-compose logs [service]
docker-compose logs -f producer

# Inspection des rÃ©seaux
docker network ls
docker network inspect streaming-analytics-docker_engnetwork

# Inspection des volumes
docker volume ls
docker volume inspect streaming-analytics-docker_postgres_data
```

### ğŸ”„ Gestion du Cycle de Vie

```bash
# RedÃ©marrer un service spÃ©cifique
docker-compose restart producer

# Mise Ã  jour d'un service
docker-compose build producer
docker-compose up -d producer

# Scaling (si supportÃ©)
docker-compose up -d --scale consumer=2
```

## ğŸ¯ Commandes Utiles

### DÃ©veloppement

```bash
# Reconstruire et redÃ©marrer
docker-compose down && docker-compose build && docker-compose up -d

# AccÃ©der Ã  un conteneur
docker-compose exec postgres bash
docker-compose exec producer bash

# Copier des fichiers
docker-compose cp local_file producer:/app/
```

### Production

```bash
# DÃ©marrage en arriÃ¨re-plan
docker-compose up -d

# Mise Ã  jour sans interruption
docker-compose up -d --no-recreate

# Backup des donnÃ©es
docker-compose exec postgres pg_dump -U yelp_user yelp_analytics > backup.sql
```

### Nettoyage

```bash
# ArrÃªter tous les services
docker-compose down

# Supprimer les volumes (âš ï¸ perte de donnÃ©es)
docker-compose down -v

# Nettoyage complet du systÃ¨me
docker system prune -af
docker volume prune -f
```

## ğŸ“ Structure du Projet ConteneurisÃ©

```
.
â”œâ”€â”€ Consumer/
â”‚   â”œâ”€â”€ Dockerfile                 # Image Spark Consumer
â”‚   â””â”€â”€ target/scala-2.12/         # JAR compilÃ©
â”œâ”€â”€ DataVisualisation/
â”‚   â”œâ”€â”€ Dockerfile                 # Image Streamlit
â”‚   â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â”‚   â””â”€â”€ src/                       # Code source
â”œâ”€â”€ Producer/
â”‚   â”œâ”€â”€ Dockerfile                 # Image Spark Producer
â”‚   â””â”€â”€ target/scala-2.12/         # JAR compilÃ©
â”œâ”€â”€ init/
â”‚   â””â”€â”€ init.sql                   # Script init PostgreSQL
â”œâ”€â”€ yelp_dataset/                  # Dataset dÃ©compressÃ©
â”œâ”€â”€ docker-compose.yml             # Orchestration
â”œâ”€â”€ .env                           # Configuration
â””â”€â”€ README.md                      # Documentation
```

## ğŸš€ FonctionnalitÃ©s de Conteneurisation

### Multi-Stage Build (RecommandÃ©)
```dockerfile
FROM openjdk:11-jdk AS builder
WORKDIR /app
COPY . .
RUN ./gradlew build

FROM openjdk:11-jre-slim AS runtime
COPY --from=builder /app/target/*.jar /app/
```

### Health Checks
```yaml
healthcheck:
  test: ["CMD-SHELL", "curl -f http://localhost:4040 || exit 1"]
  interval: 30s
  timeout: 10s
  retries: 3
```

### Resource Limits
```yaml
deploy:
  resources:
    limits:
      cpus: '2.0'
      memory: 2G
    reservations:
      cpus: '1.0'
      memory: 1G
```

## ğŸ” Validation du Projet

VÃ©rifiez que votre conteneurisation fonctionne :

```bash
# Tous les conteneurs sont UP
docker-compose ps

# Les services communiquent
docker-compose exec producer ping kafka
docker-compose exec consumer ping postgres

# Les donnÃ©es circulent
docker-compose logs producer | grep "Batch"
docker-compose logs consumer | grep "Processing"

# L'interface web est accessible
curl http://localhost:8501
```

## ğŸ“ CompÃ©tences DÃ©montrÃ©es

Ce projet met en Ã©vidence :
- **Dockerisation** d'applications complexes
- **Orchestration** multi-conteneurs
- **Gestion des rÃ©seaux** et isolation
- **Persistance des donnÃ©es** avec volumes
- **Configuration** externalisÃ©e
- **Monitoring** et debugging
- **SÃ©curitÃ©** des conteneurs
- **Optimisation** des performances

---

**Note** : Ce projet est conÃ§u pour dÃ©montrer une maÃ®trise complÃ¨te de la conteneurisation Docker dans un contexte d'architecture microservices.
